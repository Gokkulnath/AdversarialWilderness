{
  
    
        "post0": {
            "title": "Research Ideas",
            "content": "Research Ideas (Outdated: 2015) . Activity recognition using Smartphone sensor. | Behavioural Diagnostics using Wireless Sensor Nodes.(Low Cost Scratch Built Node: Maniacbug) | Walk Style Monitoring and Categorizing based on IMU Sensor. | Micro Controller based Highly sensitive/precise power source for Critical Application (Programmable IC) | Use MicroUSB 3.0 OTG based hardware: Derive Power from Phone Battery: Develop Interface to Directly Connect Biomed Hardware and Process data using the Usb Interface. | Contactless ECG based on Micro Controller and Smartphone Realtime Signal Monitoring. | Emotion/Mood Detection ?? | ArduSpectro: Affordable spectrophotometry remains a challenge in the developing world and for mobile diagnostic teams in a domestic disaster response. | By using novel digital signal algorithms and off the shelf electronic components, the MIT team led by Dr. Paulino Vacas Jacques has created a | low-cost spectrophotomer used for disease and environmental marker detection | Smart Rectifier: Circuit Level Design to Optimise Power loss : SMPS/ Mobile Chargers | Microcotroller based Electric Energy Meters : Reduce Power Theft and Accurate Measurement of Power. | Any Machine Learning algorithm deployed on Embedded Controller. | Road Traffic Decongestion / Traffic optimisation using Clustering/Machine Learning approach. | Vechicle Collision avoidance using Ultrasonic Sensor Network based System . | Lifi/Bio Metric Based- Capacitive Sensor Based Security System | Speech Based Assistance to Blind People Using Deep Learning Architectures. | Adaptive Noise Cancellers/ Noise Supressers At Hospitals/Library. adaptive noise cancellation issues. echo cancellation |",
            "url": "/adversarialwilderness/ideas/2020/03/30/Research-Ideas-College.html",
            "relUrl": "/ideas/2020/03/30/Research-Ideas-College.html",
            "date": " • Mar 30, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Post 0: Adversarial Machine Learning Paper Reading Challenge",
            "content": "Paper Summary Series Road-map : . Top 30 Key Research papers to get the necessary fundamental papers that anyone who wants to perform neural network evaluations should read. The papers are split by topic and indicated which topics should be read before others. (List shared by Nicholas Carlini ) . Preliminary Papers . [ ] Evasion Attacks against Machine Learning at Test Time | [ ] Intriguing properties of neural networks | [ ] Explaining and Harnessing Adversarial Examples | . Attacks [requires Preliminary Papers] . [ ] The Limitations of Deep Learning in Adversarial Settings | [ ] DeepFool: a simple and accurate method to fool deep neural networks | [ ] Towards Evaluating the Robustness of Neural Networks | . Transferability [requires Preliminary Papers] . [ ] Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples | [ ] Delving into Transferable Adversarial Examples and Black-box Attacks | [ ] Universal adversarial perturbations | . Detecting Adversarial Examples [requires Attacks, Transferability] . [ ] On Detecting Adversarial Perturbations | [ ] Detecting Adversarial Samples from Artifacts | [ ] Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods | . Restricted Threat Model Attacks [requires Attacks] . [ ] ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks without Training Substitute Models | [ ] Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models | [ ] Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors | . Physical-World Attacks [reqires Attacks, Transferability] . [ ] Adversarial examples in the physical world | [ ] Synthesizing Robust Adversarial Examples | [ ] Robust Physical-World Attacks on Deep Learning Models | . Verification [requires Introduction] . [ ] Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks | [ ] On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models | . Defenses (2) [requires Detecting] . [ ] Towards Deep Learning Models Resistant to Adversarial Attacks | [ ] Certified Robustness to Adversarial Examples with Differential Privacy | . Attacks (2) [requires Defenses (2)] . [ ] Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples | [ ] Adversarial Risk and the Dangers of Evaluating Against Weak Attacks | . Defenses (3) [requires Attacks (2)] . [ ] Towards the first adversarially robust neural network model on MNIST | [ ] On Evaluating Adversarial Robustness | . Other Domains [requires Attacks] . [ ] Adversarial Attacks on Neural Network Policies | [ ] Audio Adversarial Examples: Targeted Attacks on Speech-to-Text | [ ] Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples | [ ] Adversarial examples for generative models | . . Visualized using Adversarial Machine Learning Reading List by Nicholas Carlini — Link . Resources . Key Researchers their affiliations: . Nicholas Carlini (Google Brain) | Anish Athalye (MIT) | Nicolas Papernot (Google Brain) | Wieland Brendel (University of Tubingen) | Jonas Rauber (University of Tubingen) | Dimitris Tsipras (MIT) | Ian Goodfellow (Google Brain) | Aleksander Madry (MIT) | Alexey Kurakin (Google Brain) | . Research Labs : . Bethge Lab : http://bethgelab.org/ | . Frameworks/Libraries: . cleverhans- Tensorflow | foolbox — Keras/Tensorflow/Pytorch | advertorch — Pytorch | .",
            "url": "/adversarialwilderness/adversarial-machine-learning/2020/02/15/Post-0-Adversarial-Machine-Learning-Paper-Reading-Challenge.html",
            "relUrl": "/adversarial-machine-learning/2020/02/15/Post-0-Adversarial-Machine-Learning-Paper-Reading-Challenge.html",
            "date": " • Feb 15, 2020"
        }
        
    
  
    
  
    
        ,"post3": {
            "title": "TorchVision: My First Pull Request",
            "content": "Feature/Bug Requested: . The classes attribute of EMNIST dataset does not take into account the split argument. From the original EMNIST dataset https://www.nist.gov/itl/products-and-services/emnist-dataset . . Understanding the Problem: . The Existing code doesn’t consider the splits parameter that is passed to the dataset. This is because the EMNIST Class inherits the Default MNIST Class and doesn’t set the classes attribute appropriately. . Solution? . I knew that overriding the classes attribute should do the job. From the details provided in the issue and from the link, I was able to create a dictionary that maps the splits into classes. I was a not confident with my solution initially, but then I tried to use it locally with my changes in place and gained confidence over my changes. Finally, I override the classes attribute to get the expected behaviour. . Key Learnings: . Always create a branch for developing a feature or fixing a bug. Working on Master branch of fork will be a mess as other features can get merger to master branch of Original repo and syncing will be difficult. | Dont be afraid to commit mistakes or submit dumb solutions. Not all solutions are great. Maintainers are there to help and will review the changes and suggest better approaches if any . | Don’t forget to lint the code before pushing a change. I had to submit a few times to get the linting part correct. | . I Know the changes are not much, but I feel thrilled that I have a PR merged in torchvision repo. Thanks for reading. I encourage you to try to contribute to any Open Source project. I can assure it will be a great learning experience .",
            "url": "/adversarialwilderness/pytorch/2020/01/11/TorchVision-PR.html",
            "relUrl": "/pytorch/2020/01/11/TorchVision-PR.html",
            "date": " • Jan 11, 2020"
        }
        
    
  
    
  
    
        ,"post5": {
            "title": "Choosing Components For Personal Deep Learning Machine",
            "content": ". Hi Everyone! . As a Hobbyist, the cost of EC2 Instances for running an experiment has been a barrier in exploring and solving Deep Learning Problems. Reserved Instances were my initial playground as i was not familiar with cloud ecosystem. . Eventually, Spot instances became *my alternative to run well structured experiments. But often times, it found it very difficult to setup and run experiments. The main problem comes when setting up the environment for backing up and restoring the data/progress. Thanks to Alex Ramos and Slav Ivanov for the Classic and 24X7 versions of the EC2 Spotter tool which came in handy when dealing with spot instances.( Try them out if you still use Spot Instances* ) . After using AWS EC2 instances for a around 6 months, I realized that the long term cheaper alternative is to invest on a local machine. This allows me to gain more by having better control over the experiment and with similar or better performance. On detailed survey throughout the internet, I couldn’t find any difference of opinion regarding the local machine idea when it comes to long term usage. Hence, I started to research on choosing components for my local deep learning build. . Selection of components for Deep learning is a a huge puzzle that intrigues many beginners who try to get their build. It requires the user to have some basic knowledge to build a system that can meet the required performance for the cost involved. . This post tries to help the fellow readers to get started with selection of components and understand the parameters before choosing the product. . So! Lets get Started!! . First things First! You must finalize on the maximum number of GPU’s that you plan to have on the newly built system. If you’re an active machine learning researcher then you might probably want more GPUs. This can help you run more than one task in parallel and try different variations of model architectures, data normalization, hyper parameters etc.. in parallel. . My Recommendations: If you are a researcher/Student/Hobbyist Consider for a Dual GPU Build. If you plan to run huge models and participate in insane contests like ImageNet which require heavy computation, consider for a Multi GPU Build. . Once you have arrived at a conclusion on the type of build you can arrive at the number of PCIe lanes required: . Dual-GPU Build (Up to 2 GPU): 24 PCIe Lanes (Might Experience Performance Lag when using SSD that share PCIe lanes or when Both GPU) | Multi-GPU Build (Up to 4 GPU’s): 40 to 44 PCIe Lanes | Why PCIe lanes first?— In practice, there will be a bottleneck to keep data flowing to the GPU because of disk access operations and/or data augmentation. A GPU would require 16 PCIe lanes to work at its full capacity. . This post will address only about Dual-GPU System. There will be a follow up post about the Multi-GPU Build. . Dual-GPU Build . 1) Motherboard: . Once the PCI-e Lane requirement has been decided, We can now choose the Motherboard Chipset: . The below table gives you the no of PCI-e Lanes available with different Chipsets available: . . Comparison of PCI-e Lanes across different Chipsets (Mostly Intel Processor Based) . Note:** Ideally a GPU, to perform at its full capacity requires **16 PCI-e Lanes. . So, even though Chipsets like B150,B250, H110,H170,H270 support Intel processors, They are seldom used for deep learning builds since the number of PCIe lanes will not be enough for Deep learning applications. . Hence, chipsets that are commonly preferred are: . Z170 — Support both 6th/7th Gen Intel Processor. Usage of 7th Gen might require a BIOS Update. Z270 — Support both 6th/7th Gen Intel Processor. (Latest) Z370 — Supports 8th Gen Intel Processor. . P.S: Will update the post once i have enough details for AMD based Chipsets . Once you have decided on the chipset, Use PC Partpicker to select the motherboard : Link to select the motherboard of your choice. . Things to Keep in Mind: . Form Factor (i.e ATX, Micro ATX, EATX etc..) | No of PCIe Slots ( Minimum 2 Slots) | Maximum RAM Supported ( 64 GB Preferred) | No of RAM Slots (Minimum 4 Slots) | SSD and SATA Slots (if you is concerned) | 2) Processors: . Through the selection of motherboards, We have narrowed down the choice of processor based on constraints like socket type, But the choice of CPU might further dependent on GPU. For Deep learning applications, As mentioned earlier, The CPU is responsible mainly for the data processing and communicating with GPU. Hence, The number of cores and threads per core is important if we want to parallelize all that data preparation. It is advised to choose a multi core system (Preferably 4 Cores)to handle these tasks. . Things to Keep in Mind: . Socket Type | No of Cores | Cost | Some processors may need the user to get their own Cooler Fan. Usually, Unboxed Processor doesn’t come with a cooler fan but allows the user to overclock. | Use PC Partpicker to select the Processor : Link . Memory or RAM: . . When working with large/big datasets we might need to have them in memory. Size of the RAM decide how much of dataset you can hold in memory. For Deep learning applications it is suggested to have a minimum of 16GB memory (Jeremy Howard Advises to get 32GB). Regarding the Clock, The higher the better. It ideally signifies the Speed — Access Time but a minimum of 2400 MHz is advised. . Always try to get more memory in a single stick as it will allow for further expansion in remaining slots.I have seen many people who get 48 GB RAM instead of 216 GB ending up using all 4 Slots and no room for upgrade just because they are bit cheap than the latter. . Storage: . The price of HDD is decreasing continuously as SSD become more affordable and faster. . . Its always better to get a small size SSD and a large HDD. SSD’s are preferred to store and retrieve data that is actively used. On the other hand HDD should be used to store data that are to be used in future. . SSD — Datasets in use + OS (Costly! Min: 128 GB Recommended) . HDD — Misc User Data (Cheaper! Min: 2 TB Recommended 7200RPM) . GPU: . GPU’s are the heart of Deep learning Build. They decide the performance gain that you get during training of neural networks. As most of the computation involved in Deep Learning are Matrix operations, GPU outperforms conventional CPU by running the same as parallel operations. They have small computation units called cores that can have threads which enable them to run the matrix operations faster. The Memory bandwidth of the GPU also enables to operate on large batches of data. . Tim Dettmers has a great article on choosing a GPU for Deep Learning, which he regularly updates as new cards come on the market. Please check them out before choosing your GPU. . Couldn’t resist to repost from Tim Dettmers Post. His TL;DR advice for choosing GPU: . Best GPU overall (by a small margin): Titan Xp . Cost efficient but expensive: GTX 1080 Ti, GTX 1070, GTX 1080 . Cost efficient and cheap: GTX 1060 (6GB) . I work with data sets &gt; 250GB: GTX Titan X (Maxwell), NVIDIA Titan X Pascal, or NVIDIA Titan Xp . I have little money: GTX 1060 (6GB) . I have almost no money: GTX 1050 Ti (4GB) . I do Kaggle: GTX 1060 (6GB) for any “normal” competition, or GTX 1080 Ti for “deep learning competitions” . I am a competitive computer vision researcher: NVIDIA Titan Xp; do not upgrade from existing Titan X (Pascal or Maxwell) . I am a researcher: GTX 1080 Ti. In some cases, like natural language processing, a GTX 1070 or GTX 1080 might also be a solid choice — check the memory requirements of your current models . I want to build a GPU cluster: This is really complicated, you can get some ideas here . I started deep learning and I am serious about it: Start with a GTX 1060 (6GB). Depending of what area, you choose next (start-up, Kaggle, research, applied deep learning) sell your GTX 1060 and buy something more appropriate . I want to try deep learning, but I am not serious about it: GTX 1050 Ti (4 or 2GB) . I strongly recommend a beginner to get a 1060 6gb (New/Used) if they are on a budget. If the budget can go up a bit then you can get a 1070ti (MSRP around 430 USD) that was released recently i.e.. OCT 26th which offers almost the same performance as 1080 but at a lower cost (Almost Same as 1070). Don’t buy a 1070 unless you have a strong reason to, instead get a 1070ti as it has a greater number of cores. If you have enough money, then get a 1080ti. (No Second Thoughts). Again, if you are very active in performing research consider buying 2 X 1070ti instead of 1 X 1080ti as it gives flexibility that’s was discussed earlier. . For readers wondering about different editions of GPU like Founder’s Edition, OC, FTW etc. . Here’s the Info that you need: . Difference between Editions: Fundamentally all of them have the same GPU processor inside them. The main difference would be variation in quality of the PCB and usually high-end models would have higher binned chips (Best Quality). . Difference between Brands: Brands build their custom PCB components and aesthetics like lighting, Multiple fans, water cooled or back plate. These are done in order to improve the performance on the reference boards by just keeping the reference design on the card and add custom coolers on it. The base clocks out of the box matters very little generally. . Water vs Air cooled GPU: — Nvidia lowers the clock rate on your GPU as it gets hot. I don’t know if there are set temperatures that trigger this, or if it’s just linear. Water cooling will keep your GPU running at top speed. . Again! please research through the different editions. I have heard that FTW to be the coolest one to get. (Silent and No heating issues) . PSU: . Once the Components are selected using PCpartpicker site, it will give a rough estimate of power usage. It’s always better to get a PSU, large (1.2 to 1.5 times estimated power) enough to handle the power. In case if you plan to add more GPU(Add 100 W per GPU) then consider buying a PSU such that it can handle that requirement too. Some PSU tend to generate noise hence research on different products based on reviews before buying. I have found that EVGA G2 series seems to be solid option to consider. . Note: Gold, Silver, Platinum described along with the product refers to the efficiency of the PSU (Heat Generation). It directly correlates to power savings. . Conclusion: . For buying the components, I strongly recommend the reader to keep an eye on r/buildapcsales and r/hardwareswap (In US) for deals and grab them instead of buying them at retail price. Open-Box components seem to be cheaper and should be considered when on stringent budget. Try to get the components in instalments instead of getting them all at once if you are not in urgent need. . Cheaper Alternative: Try to get an Open-Box Pre-Built System and modify the components as per your requirement. (For Lazy Folks!) . The information described are based on my research and understanding from multiple articles and build guides from the internet. If there are any errors, please kindly notify me so that I can fix them. Feel free to contact me or comment below if have any questions. Thanks for reading! . Comparison of No of PCI-e Lanes across 200+ Chipsets (https://www.pugetsystems.com/labs/articles/Z270-H270-Q270-Q250-B250—What-is-the-Difference-876/) | Comparison of No of PCI-e Lanes across 100+ Chipsets ( https://www.pugetsystems.com/labs/articles/Z170-H170-H110-B170-Q150-Q170—What-is-the-Difference-635/) | ai Discussion Forum(Might require a Signup) (http://forums.fast.ai/t/making-your-own-server/174/506) | PC Part Picker: https://pcpartpicker.com | Choosing GPU for Deep learning (http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/) | The $1700 Deep Learning box (https://blog.slavv.com/the-1700-great-deep-learning-box-assembly-setup-and-benchmarks-148c5ebe6415) | FAQ &amp; Miscellaneous : . CPU Lanes vs PCI-e Lanes: . PCIe lane denotes the maximum bandwidth that is available for graphics cards’ communication with the CPU. Having more lanes than you need won’t increase performance, you just don’t want to have so few that it starts restricting CPU/GPU intercommunication. Generally an x8 lane of PCIe 3.0 has more than enough bandwidth for any gaming card, so 16 lanes for dual cards or 24 lanes for triple cards is fine. In applications outside of gaming, such as when the GPU is being used to accelerate CPU computation for workstations and servers, there is a lot more communication between the CPU and GPU than in games, so 40 lanes might be helpful there. The X99 platform is derived from Intel’s server/workstation chips, so that’s why they have so many lanes. . Source: Link .",
            "url": "/adversarialwilderness/misc-advice/2017/11/21/Choosing-Components-for-Personal-Deep-Learning-Machine.html",
            "relUrl": "/misc-advice/2017/11/21/Choosing-Components-for-Personal-Deep-Learning-Machine.html",
            "date": " • Nov 21, 2017"
        }
        
    
  
    
        ,"post6": {
            "title": "A Novel Clustered Support Vector Machine with Reduced Support Vectors for Big Data Classification",
            "content": "If you are not redirected automatically, follow this link to get to know about the project. You can find the code related to the project at Code. .",
            "url": "/adversarialwilderness/machine%20learning/2016/03/11/Clustered-SVM.html",
            "relUrl": "/machine%20learning/2016/03/11/Clustered-SVM.html",
            "date": " • Mar 11, 2016"
        }
        
    
  

  
  

  

  
      ,"page2": {
          "title": "About Me",
          "content": "If you are not redirected automatically, follow this link to get to know about me. .",
          "url": "/adversarialwilderness/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  
      ,"page5": {
          "title": "News!",
          "content": "Current Works . Achievements . Ericsson Impact AWARD - 2018 from Head of Business Area Managed Services | 1 out of 15 Top Performers for 2018-2019 in BMAS Service Assurance MS IT &amp; ADM Unit. | . Activities! . Ericsson Internal Trainer for Machine Learning and Python Competence development. Trained more than 50 Colleagues and enabled them to apply machine learning to Telecom and IT industry. | External Internship Participant @Inkers.ai - EIP 2 and EIP 3 | AI Saturdays : Ambassador for Bangalore Chapter: Cycle 1 Testimonial | Fast.AI international Fellow | One of the 15 Selected Outreach Participant to attend Computational Science Symposium (CSS-2017) | .",
          "url": "/adversarialwilderness/News/",
          "relUrl": "/News/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "/adversarialwilderness/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}