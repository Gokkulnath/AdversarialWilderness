<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Evasion attacks against machine learning at test time : [1708.06131] | Adversarial Wilderness</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Evasion attacks against machine learning at test time : [1708.06131]" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="TLDR :" />
<meta property="og:description" content="TLDR :" />
<link rel="canonical" href="https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1708.06131.html" />
<meta property="og:url" content="https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1708.06131.html" />
<meta property="og:site_name" content="Adversarial Wilderness" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-02-16T00:00:00-06:00" />
<script type="application/ld+json">
{"headline":"Evasion attacks against machine learning at test time : [1708.06131]","dateModified":"2020-02-16T00:00:00-06:00","datePublished":"2020-02-16T00:00:00-06:00","url":"https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1708.06131.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1708.06131.html"},"description":"TLDR :","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://blog.gokkulnath.ml/feed.xml" title="Adversarial Wilderness" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-149929011-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Adversarial Wilderness</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/cv/">CV</a><a class="page-link" href="/News/">News!</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Evasion attacks against machine learning at test time : [1708.06131]</h1><p class="page-description">TLDR :  </p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-02-16T00:00:00-06:00" itemprop="datePublished">
        Feb 16, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#PaperReview">PaperReview</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/# Adversarial Machine Learning"> Adversarial Machine Learning</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#evasion-attacks-against-machine-learning-at-test-time--170806131">Evasion attacks against machine learning at test time : [1708.06131]</a>
<ul>
<li class="toc-entry toc-h2"><a href="#desired-proactive-protection-mechanisms">Desired proactive protection mechanisms</a></li>
<li class="toc-entry toc-h2"><a href="#adversarys-goal">Adversary’s goal:</a></li>
<li class="toc-entry toc-h2"><a href="#adversary-knowledge-attackers-knowledge-about-the-system">Adversary Knowledge (Attackers Knowledge about the system,):</a></li>
<li class="toc-entry toc-h2"><a href="#adversarys-capability">Adversary’s capability.:</a></li>
<li class="toc-entry toc-h2"><a href="#attack-scenarios-">Attack Scenarios :</a></li>
<li class="toc-entry toc-h2"><a href="#gradient-descent-attacks">Gradient descent attacks</a>
<ul>
<li class="toc-entry toc-h4"><a href="#to-do-">TO DO :</a></li>
</ul>
</li>
</ul>
</li>
</ul><h1 id="evasion-attacks-against-machine-learning-at-test-time--170806131">
<a class="anchor" href="#evasion-attacks-against-machine-learning-at-test-time--170806131" aria-hidden="true"><span class="octicon octicon-link"></span></a>Evasion attacks against machine learning at test time : [1708.06131]</h1>

<h2 id="desired-proactive-protection-mechanisms">
<a class="anchor" href="#desired-proactive-protection-mechanisms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Desired proactive protection mechanisms</h2>
<ol>
  <li>finding potential vulnerabilities of learning before they are exploited by the adversary;</li>
  <li>investigating the impact of the corresponding attacks (i.e., evaluating classifier security);</li>
  <li>devising appropriate countermeasures if an attack is found to significantly degrade the classifier’s performance</li>
</ol>

<p>General approach is to use Game-theory approach attacker vs defense till it reaches Nash equilibrium. but realsitic constaints are too hard to be incorporated into game theory</p>
<h2 id="adversarys-goal">
<a class="anchor" href="#adversarys-goal" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adversary’s goal:</h2>
<ul>
  <li>Adversary’s goal should be defined in terms of a utility (loss) function that the adversary seeks to maximize (minimize).</li>
  <li>In the evasion setting, the attacker’s goal is to manipulate a single (without loss of generality, positive) sample that should be misclassified.</li>
</ul>

<h2 id="adversary-knowledge-attackers-knowledge-about-the-system">
<a class="anchor" href="#adversary-knowledge-attackers-knowledge-about-the-system" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adversary Knowledge (Attackers Knowledge about the system,):</h2>
<ul>
  <li>the training set or part of it;</li>
  <li>the feature representation of each sample; i.e., how real objects such as emails, network packets are mapped into the classifier’s feature space;</li>
  <li>the type of a learning algorithm and the form of its decision function;</li>
  <li>the (trained) classifier model; e.g., weights of a linear classifier;</li>
  <li>or feedback from the classifier; e.g., classifier labels for samples chosen by the adversary.</li>
</ul>

<h2 id="adversarys-capability">
<a class="anchor" href="#adversarys-capability" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adversary’s capability.:</h2>
<p>In the evasion scenario, the adversary’s capability is limited to modifications of test data; i.e.altering the training data is not allowed.
However, under this restriction, variations in attacker’s power may include:</p>
<ul>
  <li>modifications to the input data (limited or unlimited);</li>
  <li>modifications to the feature vectors (limited or unlimited);</li>
  <li>or independent modifications to specific features (the semantics of the input data may dictate that certain features are interdependent).</li>
</ul>

<h2 id="attack-scenarios-">
<a class="anchor" href="#attack-scenarios-" aria-hidden="true"><span class="octicon octicon-link"></span></a>Attack Scenarios :</h2>
<p>Perfect knowledge (PK) –&gt; The adversary knows the feature space, the type of the classifier, and the trained model.he adversary can transform attack points in the test data but must remain within a maximum distance of dmax from the original attack sample. Dmax constraint is added to make sure the semantic meaning from the real data is not lost. 
Limited knowledge (LK). The attacker knows the feature representation and the type of the classifier, but does not know either the learned classifier f  or its training data  D , and hence can not directly compute  g(x). But the advesary has access to surrogate dataset D’ from the same underlying distribution as D. This can be done by sniffing some network traffic during the classifier operation, or by collecting legitimate samples from alternate source.  Under this scenario , we try to approximate\mimic the original classifier by trainning on the surrogate dataset with similar settings. Amount of Surrogate data is a attack hyper parameter .</p>

<p>well-known techniques, like gradient descent, or quadratic techniques such as Newton’s method, BFGS, or L-BFGS can be used to optimize this non linear optimization problem</p>

<p>when using gradient descent approach on non convex problems, we don’t have guarantee to arrive at global minima always. Hence at local minima the performance of the adversary will be poor and may not evade depending on the behavior of g(Approximated Function). To Overcome the effect/possiblity of local minima we add a λ* penalizer KDE (Kernel Density Estimator )  with bandwidth h. a.k.a (mimicry component.)
The extra component favors attack points that imitate features of known legitimate samples. Which in turn  reshapes the objective function and thereby biases the resulting gradient descent towards regions where the negative class is concentrated</p>

<h2 id="gradient-descent-attacks">
<a class="anchor" href="#gradient-descent-attacks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gradient descent attacks</h2>

<h4 id="to-do-">
<a class="anchor" href="#to-do-" aria-hidden="true"><span class="octicon octicon-link"></span></a>TO DO :</h4>
<p>Section 3 Redo : pseudo code to python translate</p>

<p>the gradient of kernel density estimators depends on the kernel gradient.</p>


  </div><a class="u-url" href="/paperreview/%20adversarial%20machine%20learning/2020/02/16/1708.06131.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Thoughts, stories and ideas. ~Gokkulnath</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/gokkulnath" title="gokkulnath"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/gokkulnath" title="gokkulnath"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
