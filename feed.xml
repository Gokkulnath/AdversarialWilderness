<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://blog.gokkulnath.ml/feed.xml" rel="self" type="application/atom+xml" /><link href="https://blog.gokkulnath.ml/" rel="alternate" type="text/html" /><updated>2021-02-10T00:46:24-06:00</updated><id>https://blog.gokkulnath.ml/feed.xml</id><title type="html">Adversarial Wilderness</title><subtitle>Thoughts, stories and ideas. ~Gokkulnath</subtitle><entry><title type="html">Support Vector Machine(SVM)</title><link href="https://blog.gokkulnath.ml/machine%20learning/2021/02/09/_SVM-Quick-Walkthrough-using-LibSVM.html" rel="alternate" type="text/html" title="Support Vector Machine(SVM)" /><published>2021-02-09T00:00:00-06:00</published><updated>2021-02-09T00:00:00-06:00</updated><id>https://blog.gokkulnath.ml/machine%20learning/2021/02/09/_SVM-Quick-Walkthrough-using-LibSVM</id><content type="html" xml:base="https://blog.gokkulnath.ml/machine%20learning/2021/02/09/_SVM-Quick-Walkthrough-using-LibSVM.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2016-02-04_SVM-Quick-Walkthrough-using-LibSVM.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Introduction&quot;&gt;Introduction&lt;a class=&quot;anchor-link&quot; href=&quot;#Introduction&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Support Vector Machine a.k.a SVM is one of the widely used classical machine learning technique since the late 1990's. This article tries to explain the internal workings of SVM and their usage using &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;LIBSVM&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/resources/SVM/SVM_Intro.png&quot; alt=&quot;&quot; title=&quot;Linear SVM Representation&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Suport-Vector-Machine-Theory&quot;&gt;Suport Vector Machine Theory&lt;a class=&quot;anchor-link&quot; href=&quot;#Suport-Vector-Machine-Theory&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let us assume a classical classification setting as shown in the image above. The solution to this problem setting is to find a decision boundary that can separate the data instances without any error and as accurate as possible.&lt;/p&gt;
&lt;p&gt;The Core Idea of SVM is to find a ideal a hyperplane(Decision Boundary) which can best fit the given data points with a desired margin. SVM's construct two decision boundaries from the ideal margins to make the classification robust. As indicated in the below figure, the two decision boundary that separates the given data with a margin. These Margins are constructed in such a way that certain point/instances (a.k.a Support Vectors) are used such that the margins pass through them.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/resources/SVM/svm1.png&quot; alt=&quot;&quot; title=&quot;Decision Boundary in SVM&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Pros-and-Cons&quot;&gt;Pros and Cons&lt;a class=&quot;anchor-link&quot; href=&quot;#Pros-and-Cons&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Based on a strong and nice Theory: Has rigorous mathematical proof and validations&lt;/li&gt;
&lt;li&gt;Training is relatively easy:&lt;ol&gt;
&lt;li&gt;No Local Optima Problem(Unlike NN)&lt;/li&gt;
&lt;li&gt;Trainning Doesnt Depend on Dimesionality of Features but only on Inputs &lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Generally avoids over-fitting: Classifier Compelxity and erros can be controlled using Hyperparams&lt;/li&gt;
&lt;li&gt;Superior classification Accuracies: Generalize well when Data is Higher Dimension/High Cardinality Features and Under small training set conditions.
&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Selection of Kernel Function is Subjective&lt;/li&gt;
&lt;li&gt;Identifying the Trade-off Hyperparameter C : Manual Search &lt;/li&gt;
&lt;li&gt;Computationally Expensive in Multiclass problem settings. (Need to Train Multiple Classifiers)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Notation-and-Concepts&quot;&gt;Notation and Concepts&lt;a class=&quot;anchor-link&quot; href=&quot;#Notation-and-Concepts&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;HyperPlane : N-Dimensional Plane (Higher Dimensions(&amp;gt;3) cannot be visualised)&lt;/li&gt;
&lt;li&gt;Decision Boundary: A Hyper plane that partitions the data into sets with each set mapping to a class.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Hyper-Parameters&quot;&gt;Hyper Parameters&lt;a class=&quot;anchor-link&quot; href=&quot;#Hyper-Parameters&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Kernel:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reglarisation Parameter (C) :&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Parameter Gamma &lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Multi-Class-vs-One-Class-SVM&quot;&gt;Multi-Class vs One-Class SVM&lt;a class=&quot;anchor-link&quot; href=&quot;#Multi-Class-vs-One-Class-SVM&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;LibSVM-Usage&quot;&gt;LibSVM Usage&lt;a class=&quot;anchor-link&quot; href=&quot;#LibSVM-Usage&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Setup-:&quot;&gt;Setup :&lt;a class=&quot;anchor-link&quot; href=&quot;#Setup-:&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Download the zip file using the url : &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/cgi-bin/libsvm.cgi?+http://www.csie.ntu.edu.tw/~cjlin/libsvm+zip&quot;&gt;link&lt;/a&gt;  and unzip the archive. Copy the contents of Python Folder into the projects master/root directory&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;A &lt;code&gt;#hide&lt;/code&gt; comment at the top of any code cell will hide &lt;strong&gt;both the input and output&lt;/strong&gt; of that cell in your blog post.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;#hide_input&lt;/code&gt; comment at the top of any code cell will &lt;strong&gt;only hide the input&lt;/strong&gt; of that cell.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Example-Use-Case:&quot;&gt;Example Use Case:&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-Use-Case:&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Charts made with Altair remain interactive.  Example charts taken from &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum&quot;&gt;this repo&lt;/a&gt;, specifically &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum/blob/master/altair_interaction.ipynb&quot;&gt;this notebook&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_breast_cancer&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_breast_cancer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;{&amp;#39;data&amp;#39;: array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,
         1.189e-01],
        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,
         8.902e-02],
        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,
         8.758e-02],
        ...,
        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,
         7.820e-02],
        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,
         1.240e-01],
        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,
         7.039e-02]]),
 &amp;#39;target&amp;#39;: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,
        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,
        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,
        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,
        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,
        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,
        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,
        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,
        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,
        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,
        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,
        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,
        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,
        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,
        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,
        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),
 &amp;#39;target_names&amp;#39;: array([&amp;#39;malignant&amp;#39;, &amp;#39;benign&amp;#39;], dtype=&amp;#39;&amp;lt;U9&amp;#39;),
 &amp;#39;DESCR&amp;#39;: &amp;#39;.. _breast_cancer_dataset:\n\nBreast cancer wisconsin (diagnostic) dataset\n--------------------------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 569\n\n    :Number of Attributes: 30 numeric, predictive attributes and the class\n\n    :Attribute Information:\n        - radius (mean of distances from center to points on the perimeter)\n        - texture (standard deviation of gray-scale values)\n        - perimeter\n        - area\n        - smoothness (local variation in radius lengths)\n        - compactness (perimeter^2 / area - 1.0)\n        - concavity (severity of concave portions of the contour)\n        - concave points (number of concave portions of the contour)\n        - symmetry \n        - fractal dimension (&amp;#34;coastline approximation&amp;#34; - 1)\n\n        The mean, standard error, and &amp;#34;worst&amp;#34; or largest (mean of the three\n        largest values) of these features were computed for each image,\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n        13 is Radius SE, field 23 is Worst Radius.\n\n        - class:\n                - WDBC-Malignant\n                - WDBC-Benign\n\n    :Summary Statistics:\n\n    ===================================== ====== ======\n                                           Min    Max\n    ===================================== ====== ======\n    radius (mean):                        6.981  28.11\n    texture (mean):                       9.71   39.28\n    perimeter (mean):                     43.79  188.5\n    area (mean):                          143.5  2501.0\n    smoothness (mean):                    0.053  0.163\n    compactness (mean):                   0.019  0.345\n    concavity (mean):                     0.0    0.427\n    concave points (mean):                0.0    0.201\n    symmetry (mean):                      0.106  0.304\n    fractal dimension (mean):             0.05   0.097\n    radius (standard error):              0.112  2.873\n    texture (standard error):             0.36   4.885\n    perimeter (standard error):           0.757  21.98\n    area (standard error):                6.802  542.2\n    smoothness (standard error):          0.002  0.031\n    compactness (standard error):         0.002  0.135\n    concavity (standard error):           0.0    0.396\n    concave points (standard error):      0.0    0.053\n    symmetry (standard error):            0.008  0.079\n    fractal dimension (standard error):   0.001  0.03\n    radius (worst):                       7.93   36.04\n    texture (worst):                      12.02  49.54\n    perimeter (worst):                    50.41  251.2\n    area (worst):                         185.2  4254.0\n    smoothness (worst):                   0.071  0.223\n    compactness (worst):                  0.027  1.058\n    concavity (worst):                    0.0    1.252\n    concave points (worst):               0.0    0.291\n    symmetry (worst):                     0.156  0.664\n    fractal dimension (worst):            0.055  0.208\n    ===================================== ====== ======\n\n    :Missing Attribute Values: None\n\n    :Class Distribution: 212 - Malignant, 357 - Benign\n\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n\n    :Donor: Nick Street\n\n    :Date: November, 1995\n\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\nhttps://goo.gl/U2Uwz2\n\nFeatures are computed from a digitized image of a fine needle\naspirate (FNA) of a breast mass.  They describe\ncharacteristics of the cell nuclei present in the image.\n\nSeparating plane described above was obtained using\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, &amp;#34;Decision Tree\nConstruction Via Linear Programming.&amp;#34; Proceedings of the 4th\nMidwest Artificial Intelligence and Cognitive Science Society,\npp. 97-101, 1992], a classification method which uses linear\nprogramming to construct a decision tree.  Relevant features\nwere selected using an exhaustive search in the space of 1-4\nfeatures and 1-3 separating planes.\n\nThe actual linear program used to obtain the separating plane\nin the 3-dimensional space is that described in:\n[K. P. Bennett and O. L. Mangasarian: &amp;#34;Robust Linear\nProgramming Discrimination of Two Linearly Inseparable Sets&amp;#34;,\nOptimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\n\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\n.. topic:: References\n\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n     for breast tumor diagnosis. IS&amp;amp;T/SPIE 1993 International Symposium on \n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n     San Jose, CA, 1993.\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n     July-August 1995.\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n     163-171.&amp;#39;,
 &amp;#39;feature_names&amp;#39;: array([&amp;#39;mean radius&amp;#39;, &amp;#39;mean texture&amp;#39;, &amp;#39;mean perimeter&amp;#39;, &amp;#39;mean area&amp;#39;,
        &amp;#39;mean smoothness&amp;#39;, &amp;#39;mean compactness&amp;#39;, &amp;#39;mean concavity&amp;#39;,
        &amp;#39;mean concave points&amp;#39;, &amp;#39;mean symmetry&amp;#39;, &amp;#39;mean fractal dimension&amp;#39;,
        &amp;#39;radius error&amp;#39;, &amp;#39;texture error&amp;#39;, &amp;#39;perimeter error&amp;#39;, &amp;#39;area error&amp;#39;,
        &amp;#39;smoothness error&amp;#39;, &amp;#39;compactness error&amp;#39;, &amp;#39;concavity error&amp;#39;,
        &amp;#39;concave points error&amp;#39;, &amp;#39;symmetry error&amp;#39;,
        &amp;#39;fractal dimension error&amp;#39;, &amp;#39;worst radius&amp;#39;, &amp;#39;worst texture&amp;#39;,
        &amp;#39;worst perimeter&amp;#39;, &amp;#39;worst area&amp;#39;, &amp;#39;worst smoothness&amp;#39;,
        &amp;#39;worst compactness&amp;#39;, &amp;#39;worst concavity&amp;#39;, &amp;#39;worst concave points&amp;#39;,
        &amp;#39;worst symmetry&amp;#39;, &amp;#39;worst fractal dimension&amp;#39;], dtype=&amp;#39;&amp;lt;U23&amp;#39;),
 &amp;#39;filename&amp;#39;: &amp;#39;C:\\Users\\Gokkulnath\\Anaconda3\\envs\\infi\\lib\\site-packages\\sklearn\\datasets\\data\\breast_cancer.csv&amp;#39;}&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;-&quot;&gt; &lt;a class=&quot;anchor-link&quot; href=&quot;#-&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;References&quot;&gt;References&lt;a class=&quot;anchor-link&quot; href=&quot;#References&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;You can display tables per the usual way in your blog:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="Machine Learning" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://blog.gokkulnath.ml/images/notebook/svm/SVM_Intro.png" /><media:content medium="image" url="https://blog.gokkulnath.ml/images/notebook/svm/SVM_Intro.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Title : [ArxivID]-[ConfID]</title><link href="https://blog.gokkulnath.ml/paperreview/%20adversarial-machine-learning/2020/07/20/Robustness-Union-models.html" rel="alternate" type="text/html" title="Title : [ArxivID]-[ConfID]" /><published>2020-07-20T00:00:00-05:00</published><updated>2020-07-20T00:00:00-05:00</updated><id>https://blog.gokkulnath.ml/paperreview/%20adversarial-machine-learning/2020/07/20/Robustness-Union-models</id><content type="html" xml:base="https://blog.gokkulnath.ml/paperreview/%20adversarial-machine-learning/2020/07/20/Robustness-Union-models.html">&lt;h1 id=&quot;title-confid&quot;&gt;Title [ConfID]&lt;/h1&gt;
&lt;h3 id=&quot;authors--auth-name-1-auth-name-2&quot;&gt;Authors : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Auth Name 1, Auth Name 2&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-Source:&quot;&gt;Arxiv URL:
Category: What type of paper is this? A measurement paper? An analysis of an existing system? A description of a research prototype?
Context: Which other papers is it related to? Which theoretical bases were used to analyze the problem?
Correctness: Do the assumptions appear to be valid?
Contributions: What are the paper's main contributions?
Clarity : Is the paper well written?

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;/images/logo.png&quot; alt=&quot;&quot; title=&quot;fast.ai's logo&quot; /&gt;
—&lt;/p&gt;
&lt;h2 id=&quot;tldr-100-200-words-&quot;&gt;TLDR (100-200 Words) :&lt;/h2&gt;

&lt;h3 id=&quot;key-motivations&quot;&gt;Key Motivations:&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Problem Addressed or Why the Paper or the idea proposed ?? *Notation* (Optional) #### Propsed Method/Technique/Idea: #### New Concepts Introduced (Optional)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;previous-results&quot;&gt;Previous Results:&lt;/h4&gt;

&lt;h3 id=&quot;experiments-conducted&quot;&gt;Experiments Conducted:&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Inferences from Table and Figures ![](/images/logo.png &quot;fast.ai's logo&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;key-conclusions&quot;&gt;Key Conclusions&lt;/h3&gt;

&lt;h2 id=&quot;possible-future-worksextensions-&quot;&gt;Possible Future Works/Extensions ?&lt;/h2&gt;
&lt;hr /&gt;</content><author><name></name></author><category term="PaperReview" /><category term=" Adversarial-Machine-Learning" /><summary type="html">Title [ConfID] Authors : Auth Name 1, Auth Name 2</summary></entry><entry><title type="html">Face Aging Using Cycle GAN</title><link href="https://blog.gokkulnath.ml/pytorch/project/2020/07/15/Face-AgingGan.html" rel="alternate" type="text/html" title="Face Aging Using Cycle GAN" /><published>2020-07-15T00:00:00-05:00</published><updated>2020-07-15T00:00:00-05:00</updated><id>https://blog.gokkulnath.ml/pytorch/project/2020/07/15/Face-AgingGan</id><content type="html" xml:base="https://blog.gokkulnath.ml/pytorch/project/2020/07/15/Face-AgingGan.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-15-Face-AgingGan.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;TLDR:&quot;&gt;TLDR:&lt;a class=&quot;anchor-link&quot; href=&quot;#TLDR:&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We Create 2 GAN with the objective to generate younger-older equivalents of old-young input images.&lt;/p&gt;
&lt;p&gt;Old --&amp;gt; Young : The Network has learned to remove wrinkles and add a lit bit of fairness to the face.&lt;/p&gt;
&lt;p&gt;Young --&amp;gt; Old : Tries to add wrinkles with a noisy patch pattern (Not perfect) and transforms eyebrow with appropriate aging effects.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;CycleGAN-Quick-Intro:&quot;&gt;CycleGAN Quick Intro:&lt;a class=&quot;anchor-link&quot; href=&quot;#CycleGAN-Quick-Intro:&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Loss-Objectives-:&quot;&gt;Loss Objectives :&lt;a class=&quot;anchor-link&quot; href=&quot;#Loss-Objectives-:&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Adversarial Loss&lt;/strong&gt;: Matching the Distribution of Generated Images to data distribution in the target domain. Similar to Normal GAN Loss, the idea is to use a discriminator network to classify the generated images as Fake or Real. In CycleGAN Case we have two discriminators which will evaluate the performance of Generators ability to model the target distribution.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cycle Consistency Loss&lt;/strong&gt; : Prevents the learned mappings of X and Y from contradicting each other.&lt;/p&gt;
&lt;p&gt;Adversarial Loss alone can map the same set of input images to any random permutation of images in the target domain, where any of the&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Identity Loss&lt;/strong&gt; (Optional) : Use only when we need to preserved the color composition between input and output(eg. Paintings to Photos) It is achieved by Regularizing the generator near an idenity mapping when real images are fed into the generator. Prevents Altering of Tint of Input images&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Results:&quot;&gt;Results:&lt;a class=&quot;anchor-link&quot; href=&quot;#Results:&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/Gokkulnath/FaceAgingGAN/master/images/old2young/image_27900.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Analysis-and-Key-Inferences&quot;&gt;Analysis and Key Inferences&lt;a class=&quot;anchor-link&quot; href=&quot;#Analysis-and-Key-Inferences&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Limitations of CycleGAN&lt;/p&gt;
&lt;p&gt;Tasks Which required Geometric Changes. (Can lead to Transfiguration)&lt;/p&gt;
&lt;p&gt;Style Transfer vs CycleGAN : Style Transfer is setup to transfer styles from a single style image/instance and optimize accordingly, while CycleGAN can generate Stylized imgaes for multiple style images/instances&lt;/p&gt;
&lt;p&gt;Horse to Zerbra: Humans also getting striped ? During trainning the model did not encounter images which have humans riding the horse or zebra&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="Pytorch" /><category term="Project" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://blog.gokkulnath.ml/images/notebook/FaceCycleGAN_banner.jpg" /><media:content medium="image" url="https://blog.gokkulnath.ml/images/notebook/FaceCycleGAN_banner.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Support Vector Machine(SVM)</title><link href="https://blog.gokkulnath.ml/machine%20learning/2020/05/24/_SVM-Quick-Walkthrough-using-LibSVM.html" rel="alternate" type="text/html" title="Support Vector Machine(SVM)" /><published>2020-05-24T00:00:00-05:00</published><updated>2020-05-24T00:00:00-05:00</updated><id>https://blog.gokkulnath.ml/machine%20learning/2020/05/24/_SVM-Quick-Walkthrough-using-LibSVM</id><content type="html" xml:base="https://blog.gokkulnath.ml/machine%20learning/2020/05/24/_SVM-Quick-Walkthrough-using-LibSVM.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2016-02-04_SVM-Quick-Walkthrough-using-LibSVM.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Introduction&quot;&gt;Introduction&lt;a class=&quot;anchor-link&quot; href=&quot;#Introduction&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Support Vector Machine a.k.a SVM is one of the widely used classical machine learning technique since the late 1990's. This article tries to explain the internal workings of SVM and their usage using &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;LIBSVM&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/resources/SVM/SVM_Intro.png&quot; alt=&quot;&quot; title=&quot;Linear SVM Representation&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Suport-Vector-Machine-Theory&quot;&gt;Suport Vector Machine Theory&lt;a class=&quot;anchor-link&quot; href=&quot;#Suport-Vector-Machine-Theory&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let us assume a classical classification setting as shown in the image above. The solution to this problem setting is to find a decision boundary that can separate the data instances without any error and as accurate as possible.&lt;/p&gt;
&lt;p&gt;The Core Idea of SVM is to find a ideal a hyperplane(Decision Boundary) which can best fit the given data points with a desired margin. SVM's construct two decision boundaries from the ideal margins to make the classification robust. As indicated in the below figure, the two decision boundary that separates the given data with a margin. These Margins are constructed in such a way that certain point/instances (a.k.a Support Vectors) are used such that the margins pass through them.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/resources/SVM/svm1.png&quot; alt=&quot;&quot; title=&quot;Decision Boundary in SVM&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Pros-and-Cons&quot;&gt;Pros and Cons&lt;a class=&quot;anchor-link&quot; href=&quot;#Pros-and-Cons&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Based on a strong and nice Theory: Has rigorous mathematical proof and validations&lt;/li&gt;
&lt;li&gt;Training is relatively easy:&lt;ol&gt;
&lt;li&gt;No Local Optima Problem(Unlike NN)&lt;/li&gt;
&lt;li&gt;Trainning Doesnt Depend on Dimesionality of Features but only on Inputs &lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Generally avoids over-fitting: Classifier Compelxity and erros can be controlled using Hyperparams&lt;/li&gt;
&lt;li&gt;Superior classification Accuracies: Generalize well when Data is Higher Dimension/High Cardinality Features and Under small training set conditions.
&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Selection of Kernel Function is Subjective&lt;/li&gt;
&lt;li&gt;Identifying the Trade-off Hyperparameter C : Manual Search &lt;/li&gt;
&lt;li&gt;Computationally Expensive in Multiclass problem settings. (Need to Train Multiple Classifiers)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Notation-and-Concepts&quot;&gt;Notation and Concepts&lt;a class=&quot;anchor-link&quot; href=&quot;#Notation-and-Concepts&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;HyperPlane : N-Dimensional Plane (Higher Dimensions(&amp;gt;3) cannot be visualised)&lt;/li&gt;
&lt;li&gt;Decision Boundary: A Hyper plane that partitions the data into sets with each set mapping to a class.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Hyper-Parameters&quot;&gt;Hyper Parameters&lt;a class=&quot;anchor-link&quot; href=&quot;#Hyper-Parameters&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Kernel:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reglarisation Parameter (C) :&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Parameter Gamma &lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Multi-Class-vs-One-Class-SVM&quot;&gt;Multi-Class vs One-Class SVM&lt;a class=&quot;anchor-link&quot; href=&quot;#Multi-Class-vs-One-Class-SVM&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;LibSVM-Usage&quot;&gt;LibSVM Usage&lt;a class=&quot;anchor-link&quot; href=&quot;#LibSVM-Usage&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Setup-:&quot;&gt;Setup :&lt;a class=&quot;anchor-link&quot; href=&quot;#Setup-:&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Download the zip file using the url : &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/cgi-bin/libsvm.cgi?+http://www.csie.ntu.edu.tw/~cjlin/libsvm+zip&quot;&gt;link&lt;/a&gt;  and unzip the archive. Copy the contents of Python Folder into the projects master/root directory&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;A &lt;code&gt;#hide&lt;/code&gt; comment at the top of any code cell will hide &lt;strong&gt;both the input and output&lt;/strong&gt; of that cell in your blog post.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;#hide_input&lt;/code&gt; comment at the top of any code cell will &lt;strong&gt;only hide the input&lt;/strong&gt; of that cell.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Example-Use-Case:&quot;&gt;Example Use Case:&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-Use-Case:&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Charts made with Altair remain interactive.  Example charts taken from &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum&quot;&gt;this repo&lt;/a&gt;, specifically &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum/blob/master/altair_interaction.ipynb&quot;&gt;this notebook&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_breast_cancer&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_breast_cancer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;{&amp;#39;data&amp;#39;: array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,
         1.189e-01],
        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,
         8.902e-02],
        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,
         8.758e-02],
        ...,
        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,
         7.820e-02],
        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,
         1.240e-01],
        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,
         7.039e-02]]),
 &amp;#39;target&amp;#39;: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,
        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,
        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,
        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,
        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,
        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,
        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,
        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,
        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,
        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,
        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,
        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,
        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,
        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,
        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,
        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),
 &amp;#39;target_names&amp;#39;: array([&amp;#39;malignant&amp;#39;, &amp;#39;benign&amp;#39;], dtype=&amp;#39;&amp;lt;U9&amp;#39;),
 &amp;#39;DESCR&amp;#39;: &amp;#39;.. _breast_cancer_dataset:\n\nBreast cancer wisconsin (diagnostic) dataset\n--------------------------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 569\n\n    :Number of Attributes: 30 numeric, predictive attributes and the class\n\n    :Attribute Information:\n        - radius (mean of distances from center to points on the perimeter)\n        - texture (standard deviation of gray-scale values)\n        - perimeter\n        - area\n        - smoothness (local variation in radius lengths)\n        - compactness (perimeter^2 / area - 1.0)\n        - concavity (severity of concave portions of the contour)\n        - concave points (number of concave portions of the contour)\n        - symmetry \n        - fractal dimension (&amp;#34;coastline approximation&amp;#34; - 1)\n\n        The mean, standard error, and &amp;#34;worst&amp;#34; or largest (mean of the three\n        largest values) of these features were computed for each image,\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n        13 is Radius SE, field 23 is Worst Radius.\n\n        - class:\n                - WDBC-Malignant\n                - WDBC-Benign\n\n    :Summary Statistics:\n\n    ===================================== ====== ======\n                                           Min    Max\n    ===================================== ====== ======\n    radius (mean):                        6.981  28.11\n    texture (mean):                       9.71   39.28\n    perimeter (mean):                     43.79  188.5\n    area (mean):                          143.5  2501.0\n    smoothness (mean):                    0.053  0.163\n    compactness (mean):                   0.019  0.345\n    concavity (mean):                     0.0    0.427\n    concave points (mean):                0.0    0.201\n    symmetry (mean):                      0.106  0.304\n    fractal dimension (mean):             0.05   0.097\n    radius (standard error):              0.112  2.873\n    texture (standard error):             0.36   4.885\n    perimeter (standard error):           0.757  21.98\n    area (standard error):                6.802  542.2\n    smoothness (standard error):          0.002  0.031\n    compactness (standard error):         0.002  0.135\n    concavity (standard error):           0.0    0.396\n    concave points (standard error):      0.0    0.053\n    symmetry (standard error):            0.008  0.079\n    fractal dimension (standard error):   0.001  0.03\n    radius (worst):                       7.93   36.04\n    texture (worst):                      12.02  49.54\n    perimeter (worst):                    50.41  251.2\n    area (worst):                         185.2  4254.0\n    smoothness (worst):                   0.071  0.223\n    compactness (worst):                  0.027  1.058\n    concavity (worst):                    0.0    1.252\n    concave points (worst):               0.0    0.291\n    symmetry (worst):                     0.156  0.664\n    fractal dimension (worst):            0.055  0.208\n    ===================================== ====== ======\n\n    :Missing Attribute Values: None\n\n    :Class Distribution: 212 - Malignant, 357 - Benign\n\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n\n    :Donor: Nick Street\n\n    :Date: November, 1995\n\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\nhttps://goo.gl/U2Uwz2\n\nFeatures are computed from a digitized image of a fine needle\naspirate (FNA) of a breast mass.  They describe\ncharacteristics of the cell nuclei present in the image.\n\nSeparating plane described above was obtained using\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, &amp;#34;Decision Tree\nConstruction Via Linear Programming.&amp;#34; Proceedings of the 4th\nMidwest Artificial Intelligence and Cognitive Science Society,\npp. 97-101, 1992], a classification method which uses linear\nprogramming to construct a decision tree.  Relevant features\nwere selected using an exhaustive search in the space of 1-4\nfeatures and 1-3 separating planes.\n\nThe actual linear program used to obtain the separating plane\nin the 3-dimensional space is that described in:\n[K. P. Bennett and O. L. Mangasarian: &amp;#34;Robust Linear\nProgramming Discrimination of Two Linearly Inseparable Sets&amp;#34;,\nOptimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\n\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\n.. topic:: References\n\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n     for breast tumor diagnosis. IS&amp;amp;T/SPIE 1993 International Symposium on \n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n     San Jose, CA, 1993.\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n     July-August 1995.\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n     163-171.&amp;#39;,
 &amp;#39;feature_names&amp;#39;: array([&amp;#39;mean radius&amp;#39;, &amp;#39;mean texture&amp;#39;, &amp;#39;mean perimeter&amp;#39;, &amp;#39;mean area&amp;#39;,
        &amp;#39;mean smoothness&amp;#39;, &amp;#39;mean compactness&amp;#39;, &amp;#39;mean concavity&amp;#39;,
        &amp;#39;mean concave points&amp;#39;, &amp;#39;mean symmetry&amp;#39;, &amp;#39;mean fractal dimension&amp;#39;,
        &amp;#39;radius error&amp;#39;, &amp;#39;texture error&amp;#39;, &amp;#39;perimeter error&amp;#39;, &amp;#39;area error&amp;#39;,
        &amp;#39;smoothness error&amp;#39;, &amp;#39;compactness error&amp;#39;, &amp;#39;concavity error&amp;#39;,
        &amp;#39;concave points error&amp;#39;, &amp;#39;symmetry error&amp;#39;,
        &amp;#39;fractal dimension error&amp;#39;, &amp;#39;worst radius&amp;#39;, &amp;#39;worst texture&amp;#39;,
        &amp;#39;worst perimeter&amp;#39;, &amp;#39;worst area&amp;#39;, &amp;#39;worst smoothness&amp;#39;,
        &amp;#39;worst compactness&amp;#39;, &amp;#39;worst concavity&amp;#39;, &amp;#39;worst concave points&amp;#39;,
        &amp;#39;worst symmetry&amp;#39;, &amp;#39;worst fractal dimension&amp;#39;], dtype=&amp;#39;&amp;lt;U23&amp;#39;),
 &amp;#39;filename&amp;#39;: &amp;#39;C:\\Users\\Gokkulnath\\Anaconda3\\envs\\infi\\lib\\site-packages\\sklearn\\datasets\\data\\breast_cancer.csv&amp;#39;}&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;-&quot;&gt; &lt;a class=&quot;anchor-link&quot; href=&quot;#-&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;References&quot;&gt;References&lt;a class=&quot;anchor-link&quot; href=&quot;#References&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;You can display tables per the usual way in your blog:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="Machine Learning" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://blog.gokkulnath.ml/images/notebook/svm/SVM_Intro.png" /><media:content medium="image" url="https://blog.gokkulnath.ml/images/notebook/svm/SVM_Intro.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Research Ideas</title><link href="https://blog.gokkulnath.ml/ideas/2020/03/30/Research-Ideas-College.html" rel="alternate" type="text/html" title="Research Ideas" /><published>2020-03-30T00:00:00-05:00</published><updated>2020-03-30T00:00:00-05:00</updated><id>https://blog.gokkulnath.ml/ideas/2020/03/30/Research-Ideas-College</id><content type="html" xml:base="https://blog.gokkulnath.ml/ideas/2020/03/30/Research-Ideas-College.html">&lt;h1 id=&quot;research-ideas-outdated-2015&quot;&gt;Research Ideas (Outdated: 2015)&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;Activity recognition using Smartphone sensor.&lt;/li&gt;
  &lt;li&gt;Behavioural Diagnostics using Wireless Sensor Nodes.(Low Cost Scratch Built Node: Maniacbug)&lt;/li&gt;
  &lt;li&gt;Walk Style Monitoring and Categorizing based on IMU Sensor.&lt;/li&gt;
  &lt;li&gt;Micro Controller based Highly sensitive/precise power source for Critical Application (Programmable IC)&lt;/li&gt;
  &lt;li&gt;Use MicroUSB 3.0 OTG based hardware: Derive Power from Phone Battery: Develop Interface to Directly Connect Biomed Hardware and Process data using the Usb Interface.&lt;/li&gt;
  &lt;li&gt;Contactless ECG based on Micro Controller and Smartphone Realtime Signal Monitoring.&lt;/li&gt;
  &lt;li&gt;Emotion/Mood Detection ??&lt;/li&gt;
  &lt;li&gt;ArduSpectro: Affordable spectrophotometry remains a challenge in the developing world and for mobile diagnostic teams in a domestic disaster response.&lt;/li&gt;
  &lt;li&gt;By using novel digital signal algorithms and off the shelf electronic components, the MIT team led by Dr. Paulino Vacas Jacques has created a&lt;/li&gt;
  &lt;li&gt;low-cost spectrophotomer used for disease and environmental marker detection&lt;/li&gt;
  &lt;li&gt;Smart Rectifier: Circuit Level Design to Optimise Power loss : SMPS/ Mobile Chargers&lt;/li&gt;
  &lt;li&gt;Microcotroller based Electric Energy Meters : Reduce Power Theft and Accurate Measurement of Power.&lt;/li&gt;
  &lt;li&gt;Any Machine Learning algorithm deployed on Embedded Controller.&lt;/li&gt;
  &lt;li&gt;Road Traffic Decongestion / Traffic optimisation using Clustering/Machine Learning approach.&lt;/li&gt;
  &lt;li&gt;Vechicle Collision avoidance using Ultrasonic Sensor Network based System .&lt;/li&gt;
  &lt;li&gt;Lifi/Bio Metric Based- Capacitive Sensor Based Security System&lt;/li&gt;
  &lt;li&gt;Speech Based Assistance to Blind People Using Deep Learning Architectures.&lt;/li&gt;
  &lt;li&gt;Adaptive Noise Cancellers/ Noise Supressers At Hospitals/Library. adaptive noise cancellation issues. echo cancellation&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="Ideas" /><summary type="html">Research Ideas (Outdated: 2015)</summary></entry><entry><title type="html">Network Adversary Generator</title><link href="https://blog.gokkulnath.ml/adversarial-machine-learning/2020/03/29/NAG-Minimal.html" rel="alternate" type="text/html" title="Network Adversary Generator" /><published>2020-03-29T00:00:00-05:00</published><updated>2020-03-29T00:00:00-05:00</updated><id>https://blog.gokkulnath.ml/adversarial-machine-learning/2020/03/29/NAG-Minimal</id><content type="html" xml:base="https://blog.gokkulnath.ml/adversarial-machine-learning/2020/03/29/NAG-Minimal.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-29-NAG-Minimal.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Introduction&quot;&gt;Introduction&lt;a class=&quot;anchor-link&quot; href=&quot;#Introduction&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;TLDR&quot;&gt;TLDR&lt;a class=&quot;anchor-link&quot; href=&quot;#TLDR&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Adversarial perturbations can pose a serious threat for deploying machine learning systems.&lt;/p&gt;
&lt;h4 id=&quot;Motivation&quot;&gt;Motivation&lt;a class=&quot;anchor-link&quot; href=&quot;#Motivation&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Current Approaches for crafting adversaries for a given classifier generate only one perturbation at a time, which is a single instance from the manifold of adversarial perturbations. In order to build robust models, it is essential to explore diverse manifold of adversarial perturbations. This work can be of very useful, when we are using adversarial trainning, where the cost of generation of adversaries is high(Depends on the attack). With this approach, we will be able to generate adversarial noises from the learned distribution of adversarial perturbations.&lt;/p&gt;
&lt;h4 id=&quot;Key-Results:&quot;&gt;Key Results:&lt;a class=&quot;anchor-link&quot; href=&quot;#Key-Results:&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;The author's demonstrate that perturbations crafted by this model&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;achieve state-of-the-art fooling rates&lt;/li&gt;
&lt;li&gt;exhibit wide variety &lt;/li&gt;
&lt;li&gt;deliver excellent cross model generalizability.&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Aproach&quot;&gt;Aproach&lt;a class=&quot;anchor-link&quot; href=&quot;#Aproach&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;The architecture of the proposed model is inspired from that of GANs and is trained using fooling and diversity objectives. The trained generator network attempts to capture the distribution of adversarial perturbations for a given classifier and readily
generates a wide variety of such perturbations.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/resources/nag.png&quot; alt=&quot;Proposed approach&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Core idea is to model the distribution of universal adversarial perturbations for a given classifier.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The image shows a batch of B random vectors {z}&lt;sub&gt;B&lt;/sub&gt; transforming into perturbations {delta}&lt;sub&gt;B&lt;/sub&gt; by G which get added to the batch of data samples {x}&lt;sub&gt;B&lt;/sub&gt;.&lt;/li&gt;
&lt;li&gt;The top portion shows adversarial batch (X&lt;sub&gt;A&lt;/sub&gt;), bottom portion shows shuffled adversarial batch (X&lt;sub&gt;S&lt;/sub&gt;) and middle portion shows the benign batch (X&lt;sub&gt;B&lt;/sub&gt;). The Fooling objective &lt;strong&gt;Lf&lt;/strong&gt; and Diversity objective &lt;strong&gt;Ld&lt;/strong&gt; constitute the loss. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; The target CNN (f) is a trained classifier and its parameters are not updated during the proposed training. On the other hand, the parameters of generator (G) are randomly initialized and learned through backpropagating the loss. (Best viewed in color).&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;em&gt;Note: Printable Version of the Entire Code disccused can be found Here: &lt;a href=&quot;https://gokkulnath.github.io/NAG_Pytorch/&quot;&gt;Link&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Github Repo : &lt;a href=&quot;https://github.com/Gokkulnath/NAG_Pytorch&quot;&gt;https://github.com/Gokkulnath/NAG_Pytorch&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Generator&quot;&gt;Generator&lt;a class=&quot;anchor-link&quot; href=&quot;#Generator&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Architecture of the generator (G): Model that is to be trained and remains unchanged for different target CNN architectures.&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/resources/DCGAN.png&quot; alt=&quot;DCGAN&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Choice of Hyperparameters&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The architecture of the generator consists of 5 deconv layers. The final deconv layer is followed by a tanh non-linearity and scaling by epsillon (10)&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Setting-up-Discriminator-:-Model-:-Architecture&quot;&gt;Setting up Discriminator : Model : Architecture&lt;a class=&quot;anchor-link&quot; href=&quot;#Setting-up-Discriminator-:-Model-:-Architecture&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Validating-Model-and-Metrics;-Ablation-Studies-Discussion&quot;&gt;Validating Model and Metrics; Ablation Studies Discussion&lt;a class=&quot;anchor-link&quot; href=&quot;#Validating-Model-and-Metrics;-Ablation-Studies-Discussion&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Fooling Rate&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;ul&gt;
&lt;li&gt;Pretrained Generator Weigths for Googlenet, Resnet50, VGG16 and VGG19 Avalaible as a Kaggle Dataset&lt;/li&gt;
&lt;li&gt;Link : &lt;a href=&quot;https://www.kaggle.com/gokkulnath/nag-pytorch-pretrained&quot;&gt;https://www.kaggle.com/gokkulnath/nag-pytorch-pretrained&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Reproducing-the-experiment:&quot;&gt;Reproducing the experiment:&lt;a class=&quot;anchor-link&quot; href=&quot;#Reproducing-the-experiment:&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Dataset and pretrained Generators cam be downloaded from this &lt;a href=&quot;https://www.kaggle.com/gokkulnath/nag-pytorch-pretrained&quot;&gt;Kaggle Dataset&lt;/a&gt; or Execute the following line after setting up kaggle api key to get the dataset
&lt;code&gt;kaggle datasets download -d gokkulnath/nag-pytorch-pretrained&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Results&quot;&gt;Results&lt;a class=&quot;anchor-link&quot; href=&quot;#Results&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Interpolating-Latent-Dimension-for-NAG&quot;&gt;Interpolating Latent Dimension for NAG&lt;a class=&quot;anchor-link&quot; href=&quot;#Interpolating-Latent-Dimension-for-NAG&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;
&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/2lojORAu8vA&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Obtained-Perturbations&quot;&gt;Obtained Perturbations&lt;a class=&quot;anchor-link&quot; href=&quot;#Obtained-Perturbations&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/resources/Collage_perturbation.v1.large.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;References:&quot;&gt;References:&lt;a class=&quot;anchor-link&quot; href=&quot;#References:&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Official Code Repo : &lt;a href=&quot;https://github.com/val-iisc/nag&quot;&gt;https://github.com/val-iisc/nag&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GAN Architecture : Pytorch Tutorial&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html?highlight=convtranspose2d#torch.nn.ConvTranspose2d&quot;&gt;Transpose Convolution Docs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="Adversarial-Machine-Learning" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://blog.gokkulnath.ml/images/notebook/nag/Collage_perturbation.v1.jpg" /><media:content medium="image" url="https://blog.gokkulnath.ml/images/notebook/nag/Collage_perturbation.v1.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Explaining and Harnessing Adversarial Examples : [1412.6572]</title><link href="https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1412.6572.html" rel="alternate" type="text/html" title="Explaining and Harnessing Adversarial Examples : [1412.6572]" /><published>2020-02-16T00:00:00-06:00</published><updated>2020-02-16T00:00:00-06:00</updated><id>https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1412.6572</id><content type="html" xml:base="https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1412.6572.html">&lt;h1 id=&quot;explaining-and-harnessing-adversarial-examples--14126572&quot;&gt;Explaining and Harnessing Adversarial Examples : [1412.6572]&lt;/h1&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;h2 id=&quot;explanation-of-adversarial-examples&quot;&gt;Explanation of Adversarial Examples&lt;/h2&gt;

&lt;h3 id=&quot;understanding-norm&quot;&gt;Understanding Norm&lt;/h3&gt;
&lt;p&gt;References: &lt;a href=&quot;https://en.wikipedia.org/wiki/Norm_(mathematics)&quot;&gt;Wiki&lt;/a&gt;
s&lt;/p&gt;

&lt;h2 id=&quot;fgsm&quot;&gt;FGSM&lt;/h2&gt;

&lt;h2 id=&quot;effect-on-deep-networks-and-weight-decay&quot;&gt;Effect on Deep Networks and Weight decay&lt;/h2&gt;

&lt;h2 id=&quot;explanation-for-transferabilty-of-perturbations&quot;&gt;Explanation for Transferabilty of Perturbations&lt;/h2&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;h2 id=&quot;key-results&quot;&gt;Key Results&lt;/h2&gt;</content><author><name></name></author><category term="PaperReview" /><category term=" Adversarial Machine Learning" /><summary type="html">Explaining and Harnessing Adversarial Examples : [1412.6572]</summary></entry><entry><title type="html">Evasion attacks against machine learning at test time : [1708.06131]</title><link href="https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1708.06131.html" rel="alternate" type="text/html" title="Evasion attacks against machine learning at test time : [1708.06131]" /><published>2020-02-16T00:00:00-06:00</published><updated>2020-02-16T00:00:00-06:00</updated><id>https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1708.06131</id><content type="html" xml:base="https://blog.gokkulnath.ml/paperreview/%20adversarial%20machine%20learning/2020/02/16/1708.06131.html">&lt;h1 id=&quot;evasion-attacks-against-machine-learning-at-test-time--170806131&quot;&gt;Evasion attacks against machine learning at test time : [1708.06131]&lt;/h1&gt;

&lt;h2 id=&quot;desired-proactive-protection-mechanisms&quot;&gt;Desired proactive protection mechanisms&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;finding potential vulnerabilities of learning before they are exploited by the adversary;&lt;/li&gt;
  &lt;li&gt;investigating the impact of the corresponding attacks (i.e., evaluating classifier security);&lt;/li&gt;
  &lt;li&gt;devising appropriate countermeasures if an attack is found to significantly degrade the classifier’s performance&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;General approach is to use Game-theory approach attacker vs defense till it reaches Nash equilibrium. but realsitic constaints are too hard to be incorporated into game theory&lt;/p&gt;
&lt;h2 id=&quot;adversarys-goal&quot;&gt;Adversary’s goal:&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Adversary’s goal should be defined in terms of a utility (loss) function that the adversary seeks to maximize (minimize).&lt;/li&gt;
  &lt;li&gt;In the evasion setting, the attacker’s goal is to manipulate a single (without loss of generality, positive) sample that should be misclassified.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;adversary-knowledge-attackers-knowledge-about-the-system&quot;&gt;Adversary Knowledge (Attackers Knowledge about the system,):&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;the training set or part of it;&lt;/li&gt;
  &lt;li&gt;the feature representation of each sample; i.e., how real objects such as emails, network packets are mapped into the classifier’s feature space;&lt;/li&gt;
  &lt;li&gt;the type of a learning algorithm and the form of its decision function;&lt;/li&gt;
  &lt;li&gt;the (trained) classifier model; e.g., weights of a linear classifier;&lt;/li&gt;
  &lt;li&gt;or feedback from the classifier; e.g., classifier labels for samples chosen by the adversary.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;adversarys-capability&quot;&gt;Adversary’s capability.:&lt;/h2&gt;
&lt;p&gt;In the evasion scenario, the adversary’s capability is limited to modifications of test data; i.e.altering the training data is not allowed.
However, under this restriction, variations in attacker’s power may include:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;modifications to the input data (limited or unlimited);&lt;/li&gt;
  &lt;li&gt;modifications to the feature vectors (limited or unlimited);&lt;/li&gt;
  &lt;li&gt;or independent modifications to specific features (the semantics of the input data may dictate that certain features are interdependent).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;attack-scenarios-&quot;&gt;Attack Scenarios :&lt;/h2&gt;
&lt;p&gt;Perfect knowledge (PK) –&amp;gt; The adversary knows the feature space, the type of the classifier, and the trained model.he adversary can transform attack points in the test data but must remain within a maximum distance of dmax from the original attack sample. Dmax constraint is added to make sure the semantic meaning from the real data is not lost. 
Limited knowledge (LK). The attacker knows the feature representation and the type of the classifier, but does not know either the learned classifier f  or its training data  D , and hence can not directly compute  g(x). But the advesary has access to surrogate dataset D’ from the same underlying distribution as D. This can be done by sniffing some network traffic during the classifier operation, or by collecting legitimate samples from alternate source.  Under this scenario , we try to approximate\mimic the original classifier by trainning on the surrogate dataset with similar settings. Amount of Surrogate data is a attack hyper parameter .&lt;/p&gt;

&lt;p&gt;well-known techniques, like gradient descent, or quadratic techniques such as Newton’s method, BFGS, or L-BFGS can be used to optimize this non linear optimization problem&lt;/p&gt;

&lt;p&gt;when using gradient descent approach on non convex problems, we don’t have guarantee to arrive at global minima always. Hence at local minima the performance of the adversary will be poor and may not evade depending on the behavior of g(Approximated Function). To Overcome the effect/possiblity of local minima we add a λ* penalizer KDE (Kernel Density Estimator )  with bandwidth h. a.k.a (mimicry component.)
The extra component favors attack points that imitate features of known legitimate samples. Which in turn  reshapes the objective function and thereby biases the resulting gradient descent towards regions where the negative class is concentrated&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent-attacks&quot;&gt;Gradient descent attacks&lt;/h2&gt;

&lt;h4 id=&quot;to-do-&quot;&gt;TO DO :&lt;/h4&gt;
&lt;p&gt;Section 3 Redo : pseudo code to python translate&lt;/p&gt;

&lt;p&gt;the gradient of kernel density estimators depends on the kernel gradient.&lt;/p&gt;</content><author><name></name></author><category term="PaperReview" /><category term=" Adversarial Machine Learning" /><summary type="html">Evasion attacks against machine learning at test time : [1708.06131]</summary></entry><entry><title type="html">Post 0: Adversarial Machine Learning Paper Reading Challenge</title><link href="https://blog.gokkulnath.ml/adversarial-machine-learning/2020/02/15/Post-0-Adversarial-Machine-Learning-Paper-Reading-Challenge.html" rel="alternate" type="text/html" title="Post 0: Adversarial Machine Learning Paper Reading Challenge" /><published>2020-02-15T00:00:00-06:00</published><updated>2020-02-15T00:00:00-06:00</updated><id>https://blog.gokkulnath.ml/adversarial-machine-learning/2020/02/15/Post-0-Adversarial-Machine-Learning-Paper-Reading-Challenge</id><content type="html" xml:base="https://blog.gokkulnath.ml/adversarial-machine-learning/2020/02/15/Post-0-Adversarial-Machine-Learning-Paper-Reading-Challenge.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-02-15-Post-0-Adversarial-Machine-Learning-Paper-Reading-Challenge.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Paper-Summary-Series-Road-map-:&quot;&gt;Paper Summary Series Road-map :&lt;a class=&quot;anchor-link&quot; href=&quot;#Paper-Summary-Series-Road-map-:&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Top 30 Key Research papers to get the necessary fundamental papers that anyone who wants to perform neural network evaluations should read. The papers are split by topic and indicated which topics should be read before others. (List shared by Nicholas Carlini )&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Preliminary-Papers&quot;&gt;Preliminary Papers&lt;a class=&quot;anchor-link&quot; href=&quot;#Preliminary-Papers&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Evasion Attacks against Machine Learning at Test Time&lt;/li&gt;
&lt;li&gt;[ ] Intriguing properties of neural networks&lt;/li&gt;
&lt;li&gt;[ ] Explaining and Harnessing Adversarial Examples&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Attacks-[requires-Preliminary-Papers]&quot;&gt;Attacks [requires Preliminary Papers]&lt;a class=&quot;anchor-link&quot; href=&quot;#Attacks-[requires-Preliminary-Papers]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] The Limitations of Deep Learning in Adversarial Settings&lt;/li&gt;
&lt;li&gt;[ ] DeepFool: a simple and accurate method to fool deep neural networks&lt;/li&gt;
&lt;li&gt;[ ] Towards Evaluating the Robustness of Neural Networks&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Transferability-[requires-Preliminary-Papers]&quot;&gt;Transferability [requires Preliminary Papers]&lt;a class=&quot;anchor-link&quot; href=&quot;#Transferability-[requires-Preliminary-Papers]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples&lt;/li&gt;
&lt;li&gt;[ ] Delving into Transferable Adversarial Examples and Black-box Attacks&lt;/li&gt;
&lt;li&gt;[ ] Universal adversarial perturbations&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Detecting-Adversarial-Examples-[requires-Attacks,-Transferability]&quot;&gt;Detecting Adversarial Examples [requires Attacks, Transferability]&lt;a class=&quot;anchor-link&quot; href=&quot;#Detecting-Adversarial-Examples-[requires-Attacks,-Transferability]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] On Detecting Adversarial Perturbations&lt;/li&gt;
&lt;li&gt;[ ] Detecting Adversarial Samples from Artifacts&lt;/li&gt;
&lt;li&gt;[ ] Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Restricted-Threat-Model-Attacks-[requires-Attacks]&quot;&gt;Restricted Threat Model Attacks [requires Attacks]&lt;a class=&quot;anchor-link&quot; href=&quot;#Restricted-Threat-Model-Attacks-[requires-Attacks]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks without Training Substitute Models&lt;/li&gt;
&lt;li&gt;[ ] Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models&lt;/li&gt;
&lt;li&gt;[ ] Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Physical-World-Attacks-[reqires-Attacks,-Transferability]&quot;&gt;Physical-World Attacks [reqires Attacks, Transferability]&lt;a class=&quot;anchor-link&quot; href=&quot;#Physical-World-Attacks-[reqires-Attacks,-Transferability]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Adversarial examples in the physical world&lt;/li&gt;
&lt;li&gt;[ ] Synthesizing Robust Adversarial Examples&lt;/li&gt;
&lt;li&gt;[ ] Robust Physical-World Attacks on Deep Learning Models&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Verification-[requires-Introduction]&quot;&gt;Verification [requires Introduction]&lt;a class=&quot;anchor-link&quot; href=&quot;#Verification-[requires-Introduction]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks&lt;/li&gt;
&lt;li&gt;[ ] On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Defenses-(2)-[requires-Detecting]&quot;&gt;Defenses (2) [requires Detecting]&lt;a class=&quot;anchor-link&quot; href=&quot;#Defenses-(2)-[requires-Detecting]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Towards Deep Learning Models Resistant to Adversarial Attacks&lt;/li&gt;
&lt;li&gt;[ ] Certified Robustness to Adversarial Examples with Differential Privacy&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Attacks-(2)-[requires-Defenses-(2)]&quot;&gt;Attacks (2) [requires Defenses (2)]&lt;a class=&quot;anchor-link&quot; href=&quot;#Attacks-(2)-[requires-Defenses-(2)]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples&lt;/li&gt;
&lt;li&gt;[ ] Adversarial Risk and the Dangers of Evaluating Against Weak Attacks&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Defenses-(3)-[requires-Attacks-(2)]&quot;&gt;Defenses (3) [requires Attacks (2)]&lt;a class=&quot;anchor-link&quot; href=&quot;#Defenses-(3)-[requires-Attacks-(2)]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Towards the first adversarially robust neural network model on MNIST&lt;/li&gt;
&lt;li&gt;[ ] On Evaluating Adversarial Robustness&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Other-Domains-[requires-Attacks]&quot;&gt;Other Domains [requires Attacks]&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-Domains-[requires-Attacks]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Adversarial Attacks on Neural Network Policies&lt;/li&gt;
&lt;li&gt;[ ] Audio Adversarial Examples: Targeted Attacks on Speech-to-Text&lt;/li&gt;
&lt;li&gt;[ ] Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples&lt;/li&gt;
&lt;li&gt;[ ] Adversarial examples for generative models&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/resources/AMLPaperReading.png&quot; alt=&quot;Visualized using Adversarial Machine Learning Reading List by Nicholas Carlini&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Visualized using Adversarial Machine Learning Reading List by Nicholas Carlini — &lt;a href=&quot;https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html&quot;&gt;Link&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Resources&quot;&gt;Resources&lt;a class=&quot;anchor-link&quot; href=&quot;#Resources&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Key-Researchers--their-affiliations:&quot;&gt;Key Researchers  their affiliations:&lt;a class=&quot;anchor-link&quot; href=&quot;#Key-Researchers--their-affiliations:&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Nicholas Carlini (Google Brain)&lt;/li&gt;
&lt;li&gt;Anish Athalye (MIT)&lt;/li&gt;
&lt;li&gt;Nicolas Papernot (Google Brain)&lt;/li&gt;
&lt;li&gt;Wieland Brendel (University of Tubingen)&lt;/li&gt;
&lt;li&gt;Jonas Rauber (University of Tubingen)&lt;/li&gt;
&lt;li&gt;Dimitris Tsipras (MIT)&lt;/li&gt;
&lt;li&gt;Ian Goodfellow (Google Brain)&lt;/li&gt;
&lt;li&gt;Aleksander Madry (MIT)&lt;/li&gt;
&lt;li&gt;Alexey Kurakin (Google Brain)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Research-Labs-:&quot;&gt;Research Labs :&lt;a class=&quot;anchor-link&quot; href=&quot;#Research-Labs-:&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Bethge Lab : &lt;a href=&quot;http://bethgelab.org/&quot;&gt;http://bethgelab.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Frameworks/Libraries:&quot;&gt;Frameworks/Libraries:&lt;a class=&quot;anchor-link&quot; href=&quot;#Frameworks/Libraries:&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;cleverhans- Tensorflow&lt;/li&gt;
&lt;li&gt;foolbox — Keras/Tensorflow/Pytorch&lt;/li&gt;
&lt;li&gt;advertorch — Pytorch&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="Adversarial-Machine-Learning" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://blog.gokkulnath.ml/images/notebook/AMLPaperReadingChallenge.png" /><media:content medium="image" url="https://blog.gokkulnath.ml/images/notebook/AMLPaperReadingChallenge.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Adversarial Machine Learning Paper Reading Challenge</title><link href="https://blog.gokkulnath.ml/adversarial-machine-learning/2020/02/15/Adversarial-Machine-Learning-Paper-Reading-Challenge.html" rel="alternate" type="text/html" title="Adversarial Machine Learning Paper Reading Challenge" /><published>2020-02-15T00:00:00-06:00</published><updated>2020-02-15T00:00:00-06:00</updated><id>https://blog.gokkulnath.ml/adversarial-machine-learning/2020/02/15/Adversarial-Machine-Learning-Paper-Reading-Challenge</id><content type="html" xml:base="https://blog.gokkulnath.ml/adversarial-machine-learning/2020/02/15/Adversarial-Machine-Learning-Paper-Reading-Challenge.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-02-15-Adversarial-Machine-Learning-Paper-Reading-Challenge.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Paper-Summary-Series-Road-map-:&quot;&gt;Paper Summary Series Road-map :&lt;a class=&quot;anchor-link&quot; href=&quot;#Paper-Summary-Series-Road-map-:&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Top 30 Key Research papers to get the necessary fundamental papers that anyone who wants to perform neural network evaluations should read. The papers are split by topic and indicated which topics should be read before others. (List shared by Nicholas Carlini )&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Preliminary-Papers&quot;&gt;Preliminary Papers&lt;a class=&quot;anchor-link&quot; href=&quot;#Preliminary-Papers&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Evasion Attacks against Machine Learning at Test Time&lt;/li&gt;
&lt;li&gt;[ ] Intriguing properties of neural networks&lt;/li&gt;
&lt;li&gt;[ ] Explaining and Harnessing Adversarial Examples&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Attacks-[requires-Preliminary-Papers]&quot;&gt;Attacks [requires Preliminary Papers]&lt;a class=&quot;anchor-link&quot; href=&quot;#Attacks-[requires-Preliminary-Papers]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] The Limitations of Deep Learning in Adversarial Settings&lt;/li&gt;
&lt;li&gt;[ ] DeepFool: a simple and accurate method to fool deep neural networks&lt;/li&gt;
&lt;li&gt;[ ] Towards Evaluating the Robustness of Neural Networks&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Transferability-[requires-Preliminary-Papers]&quot;&gt;Transferability [requires Preliminary Papers]&lt;a class=&quot;anchor-link&quot; href=&quot;#Transferability-[requires-Preliminary-Papers]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples&lt;/li&gt;
&lt;li&gt;[ ] Delving into Transferable Adversarial Examples and Black-box Attacks&lt;/li&gt;
&lt;li&gt;[ ] Universal adversarial perturbations&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Detecting-Adversarial-Examples-[requires-Attacks,-Transferability]&quot;&gt;Detecting Adversarial Examples [requires Attacks, Transferability]&lt;a class=&quot;anchor-link&quot; href=&quot;#Detecting-Adversarial-Examples-[requires-Attacks,-Transferability]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] On Detecting Adversarial Perturbations&lt;/li&gt;
&lt;li&gt;[ ] Detecting Adversarial Samples from Artifacts&lt;/li&gt;
&lt;li&gt;[ ] Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Restricted-Threat-Model-Attacks-[requires-Attacks]&quot;&gt;Restricted Threat Model Attacks [requires Attacks]&lt;a class=&quot;anchor-link&quot; href=&quot;#Restricted-Threat-Model-Attacks-[requires-Attacks]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks without Training Substitute Models&lt;/li&gt;
&lt;li&gt;[ ] Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models&lt;/li&gt;
&lt;li&gt;[ ] Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Physical-World-Attacks-[reqires-Attacks,-Transferability]&quot;&gt;Physical-World Attacks [reqires Attacks, Transferability]&lt;a class=&quot;anchor-link&quot; href=&quot;#Physical-World-Attacks-[reqires-Attacks,-Transferability]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Adversarial examples in the physical world&lt;/li&gt;
&lt;li&gt;[ ] Synthesizing Robust Adversarial Examples&lt;/li&gt;
&lt;li&gt;[ ] Robust Physical-World Attacks on Deep Learning Models&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Verification-[requires-Introduction]&quot;&gt;Verification [requires Introduction]&lt;a class=&quot;anchor-link&quot; href=&quot;#Verification-[requires-Introduction]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks&lt;/li&gt;
&lt;li&gt;[ ] On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Defenses-(2)-[requires-Detecting]&quot;&gt;Defenses (2) [requires Detecting]&lt;a class=&quot;anchor-link&quot; href=&quot;#Defenses-(2)-[requires-Detecting]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Towards Deep Learning Models Resistant to Adversarial Attacks&lt;/li&gt;
&lt;li&gt;[ ] Certified Robustness to Adversarial Examples with Differential Privacy&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Attacks-(2)-[requires-Defenses-(2)]&quot;&gt;Attacks (2) [requires Defenses (2)]&lt;a class=&quot;anchor-link&quot; href=&quot;#Attacks-(2)-[requires-Defenses-(2)]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples&lt;/li&gt;
&lt;li&gt;[ ] Adversarial Risk and the Dangers of Evaluating Against Weak Attacks&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Defenses-(3)-[requires-Attacks-(2)]&quot;&gt;Defenses (3) [requires Attacks (2)]&lt;a class=&quot;anchor-link&quot; href=&quot;#Defenses-(3)-[requires-Attacks-(2)]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Towards the first adversarially robust neural network model on MNIST&lt;/li&gt;
&lt;li&gt;[ ] On Evaluating Adversarial Robustness&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Other-Domains-[requires-Attacks]&quot;&gt;Other Domains [requires Attacks]&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-Domains-[requires-Attacks]&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;[ ] Adversarial Attacks on Neural Network Policies&lt;/li&gt;
&lt;li&gt;[ ] Audio Adversarial Examples: Targeted Attacks on Speech-to-Text&lt;/li&gt;
&lt;li&gt;[ ] Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples&lt;/li&gt;
&lt;li&gt;[ ] Adversarial examples for generative models&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/resources/AMLPaperReading.png&quot; alt=&quot;Visualized using Adversarial Machine Learning Reading List by Nicholas Carlini&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Visualized using Adversarial Machine Learning Reading List by Nicholas Carlini — &lt;a href=&quot;https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html&quot;&gt;Link&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Resources&quot;&gt;Resources&lt;a class=&quot;anchor-link&quot; href=&quot;#Resources&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Key-Researchers--their-affiliations:&quot;&gt;Key Researchers  their affiliations:&lt;a class=&quot;anchor-link&quot; href=&quot;#Key-Researchers--their-affiliations:&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Nicholas Carlini (Google Brain)&lt;/li&gt;
&lt;li&gt;Anish Athalye (MIT)&lt;/li&gt;
&lt;li&gt;Nicolas Papernot (Google Brain)&lt;/li&gt;
&lt;li&gt;Wieland Brendel (University of Tubingen)&lt;/li&gt;
&lt;li&gt;Jonas Rauber (University of Tubingen)&lt;/li&gt;
&lt;li&gt;Dimitris Tsipras (MIT)&lt;/li&gt;
&lt;li&gt;Ian Goodfellow (Google Brain)&lt;/li&gt;
&lt;li&gt;Aleksander Madry (MIT)&lt;/li&gt;
&lt;li&gt;Alexey Kurakin (Google Brain)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Research-Labs-:&quot;&gt;Research Labs :&lt;a class=&quot;anchor-link&quot; href=&quot;#Research-Labs-:&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Bethge Lab : &lt;a href=&quot;http://bethgelab.org/&quot;&gt;http://bethgelab.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Frameworks/Libraries:&quot;&gt;Frameworks/Libraries:&lt;a class=&quot;anchor-link&quot; href=&quot;#Frameworks/Libraries:&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;cleverhans- Tensorflow&lt;/li&gt;
&lt;li&gt;foolbox — Keras/Tensorflow/Pytorch&lt;/li&gt;
&lt;li&gt;advertorch — Pytorch&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="Adversarial-Machine-Learning" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://blog.gokkulnath.ml/images/notebook/AMLPaperReadingChallenge.png" /><media:content medium="image" url="https://blog.gokkulnath.ml/images/notebook/AMLPaperReadingChallenge.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>